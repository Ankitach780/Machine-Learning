{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42f0e31b",
   "metadata": {},
   "source": [
    "# Fruit Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"fruit_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c314c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82765181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[['fruit_label','fruit_name']]\n",
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff8ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fruit_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37909a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X=df[['mass','width','height']]\n",
    "Y=df['fruit_label']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67771bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler    # Normalization\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24525f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6323ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size =.20,random_state=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23643b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52269c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd081baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4afbf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "print(\"Accuracy is\",accuracy_score(y_test, y_pred))\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de697ee8",
   "metadata": {},
   "source": [
    "# Fake/Genuine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc402a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff29728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"fgusers.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39690ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30583cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier,AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE,RFECV\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,matthews_corrcoef,confusion_matrix,recall_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_accuracy_and_heatmap(model,x,y):\n",
    "    ac=accuracy_score(y,model_predict(x))\n",
    "    f_score=f1_score(y,model_predict(x))\n",
    "    cm=confusion_matrix(y,model_predict(x))\n",
    "    print(\"Accuracy:\",ac)\n",
    "    print(\"F1 score:\",f_score)\n",
    "    print(\"Confusion Matrix:\",cm)\n",
    "    print(pd.crosstab(pd.Series(model.predict(x),name=\"Predict\"),pd.Series(y['result'],name=\"Actual\")))\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773f2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder =LabelEncoder()\n",
    "\n",
    "df['name']= label_encoder.fit_transform(df['name'])\n",
    "df['screen_name']= label_encoder.fit_transform(df['screen_name'])\n",
    "df['created_at']= label_encoder.fit_transform(df['created_at'])\n",
    "df['url']= label_encoder.fit_transform(df['url'])\n",
    "df['lang']= label_encoder.fit_transform(df['lang'])\n",
    "df['time_zone']= label_encoder.fit_transform(df['time_zone'])\n",
    "df['location)']= label_encoder.fit_transform(df['location'])\n",
    "df['profile_image_url']= label_encoder.fit_transform(df['profile_image_url'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8bacba",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_columns = list(set(df.columns) - set(df._get_numeric_data().columns))\n",
    "categorical_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ca652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feature_columns = list(df._get_numeric_data().columns)\n",
    "numerical_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ec8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'listed_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b7566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 50  # number of variables for heatmap\n",
    "cols = df[numerical_feature_columns].corr().nlargest(k, target)[target].index\n",
    "cm = df[cols].corr()\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(cm, annot=True, cmap='viridis')   #optimal features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03acd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,df.columns!=target]\n",
    "y=df.iloc[:,df.columns==target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b833ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm=svm.SVC(kernel='linear')\n",
    "svm.fit(X_train,y_train)\n",
    "prediction = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = svm.score(X_test, y_test)\n",
    "print('accuracy on the svm training subset:{:.3f}'.format(svm.score(X_train,y_train)))\n",
    "print('accuracy on the svm testing subset:{:.5f}'.format(svm.score(X_test,y_test)))\n",
    "print ('svm Accuracy:', accuracy_score(y_test, prediction))\n",
    "print ('svm F1 score:', f1_score(y_test, prediction))\n",
    "print ('svm Recall:', recall_score(y_test, prediction))\n",
    "print ('svm Precision:', precision_score(y_test, prediction))\n",
    "print ('svm mcc:', matthews_corrcoef(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b14204",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3f7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, matthews_corrcoef\n",
    "\n",
    "# Generate some random data for demonstration\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8742ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc0e830",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = svm.SVC(kernel='linear')\n",
    "\n",
    "# Fit the SVM model to the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "prediction = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = svm_classifier.score(X_test, y_test)\n",
    "print('accuracy on the SVM training subset: {:.3f}'.format(svm_classifier.score(X_train, y_train)))\n",
    "print('accuracy on the SVM testing subset: {:.5f}'.format(svm_classifier.score(X_test, y_test)))\n",
    "print('SVM Accuracy:', accuracy_score(y_test, prediction))\n",
    "print('SVM F1 score:', f1_score(y_test, prediction))\n",
    "print('SVM Recall:', recall_score(y_test, prediction))\n",
    "print('SVM Precision:', precision_score(y_test, prediction))\n",
    "print('SVM MCC:', matthews_corrcoef(y_test, prediction))\n",
    "\n",
    "# Plotting the decision boundaries\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                     np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "Z = svm_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.Paired)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.scatter(svm_classifier.support_vectors_[:, 0], svm_classifier.support_vectors_[:, 1],\n",
    "            s=100, facecolors='none', edgecolors='k', linewidths=1.5, label='Support Vectors')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('SVM with Linear Kernel Decision Boundaries')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Plotting the decision boundaries\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                     np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "Z = svm_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.Paired)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.scatter(svm_classifier.support_vectors_[:, 0], svm_classifier.support_vectors_[:, 1],\n",
    "            s=100, facecolors='none', edgecolors='k', linewidths=1.5, label='Support Vectors')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('SVM with Linear Kernel Decision Boundaries')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feebf17",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a7c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate some random data for demonstration\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fit the Decision Tree model to the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print('accuracy on the DT testing subset:{:.5f}'.format(classifier.score(X_test,y_test)))\n",
    "print ('Accuracy:', accuracy_score(y_test, pred))\n",
    "print ('F1 score on the DT testing subset:{:.2f}'.format(f1_score(y_test, pred)))\n",
    "print ('DT Precision:', precision_score(y_test, pred))\n",
    "print (' DT mcc on the testing subset:{:.2f}'.format( matthews_corrcoef(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ce515",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                     np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.Paired)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Decision Tree Classifier Decision Boundaries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b9ed0c",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0583e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, matthews_corrcoef\n",
    "\n",
    "# Generate some random data for demonstration\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the Random Forest model to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "prediction = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = rf_classifier.score(X_test, y_test)\n",
    "print('Accuracy on the Random Forest training subset: {:.3f}'.format(rf_classifier.score(X_train, y_train)))\n",
    "print('Accuracy on the Random Forest testing subset: {:.5f}'.format(rf_classifier.score(X_test, y_test)))\n",
    "print('Random Forest Accuracy:', accuracy_score(y_test, prediction))\n",
    "print('Random Forest F1 score:', f1_score(y_test, prediction))\n",
    "print('Random Forest Recall:', recall_score(y_test, prediction))\n",
    "print('Random Forest Precision:', precision_score(y_test, prediction))\n",
    "print('Random Forest MCC:', matthews_corrcoef(y_test, prediction))\n",
    "\n",
    "# Plotting the decision boundaries\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                     np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "Z = rf_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.Paired)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Random Forest Decision Boundaries')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835a34f3",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab6f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, tree\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, matthews_corrcoef\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate some random data for demonstration\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the individual classifiers\n",
    "svm_classifier = svm.SVC(kernel='linear', probability=True)\n",
    "dt_classifier = tree.DecisionTreeClassifier()\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create an ensemble classifier\n",
    "ensemble_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', svm_classifier),\n",
    "        ('dt', dt_classifier),\n",
    "        ('rf', rf_classifier)\n",
    "    ],\n",
    "    voting='soft'  # Use soft voting to consider predicted probabilities\n",
    ")\n",
    "\n",
    "# Fit the ensemble classifier to the training data\n",
    "ensemble_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "ensemble_prediction = ensemble_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble classifier\n",
    "accuracy = accuracy_score(y_test, ensemble_prediction)\n",
    "print('Accuracy on the ensemble training subset: {:.3f}'.format(ensemble_classifier.score(X_train, y_train)))\n",
    "print('Accuracy on the ensemble testing subset: {:.5f}'.format(ensemble_classifier.score(X_test, y_test)))\n",
    "print('Ensemble Accuracy:', accuracy_score(y_test, ensemble_prediction))\n",
    "print('Ensemble F1 score:', f1_score(y_test, ensemble_prediction))\n",
    "print('Ensemble Recall:', recall_score(y_test, ensemble_prediction))\n",
    "print('Ensemble Precision:', precision_score(y_test, ensemble_prediction))\n",
    "print('Ensemble MCC:', matthews_corrcoef(y_test, ensemble_prediction))\n",
    "\n",
    "# Plotting the decision boundaries\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                     np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "Z = ensemble_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.Paired)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Ensemble Classifier Decision Boundaries')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab635be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
